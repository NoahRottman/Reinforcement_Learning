{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y|\u001b[43m \u001b[0m: |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Taxi-v2\")\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = env.action_space.n\n",
    "state_size = env.observation_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the action size, (number of columns) is: 6\n",
      "the state size, (number of rows) is: 500\n"
     ]
    }
   ],
   "source": [
    "#showing action and state space sizes\n",
    "print(\"the action size, (number of columns) is:\", action_size)\n",
    "print(\"the state size, (number of rows) is:\", state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Creating the Qtable\n",
    "Qtable = np.zeros((state_size,action_size))\n",
    "print(Qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_episodes = 50000\n",
    "test_episodes = 100 \n",
    "max_moves = 99 #max amount of moves allowed\n",
    "learning_rate = 0.7 #how fast our agent learns\n",
    "gamma = 0.618 #this value represents how much our agent values future rewards (direct relationship)\n",
    "\n",
    "#Exlopration vs. Exploitation\n",
    "epsilon = 1.0 #Very expolorative initially (we know nothing at the beginning)\n",
    "max_epsilon = 1.0 \n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.01 #decrease exploration rate to allow for exploitation of knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's do some Q learning!\n",
    "\n",
    "for episode in range(number_episodes):\n",
    "    state= env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    \n",
    "    for step in range(max_moves):\n",
    "        eVe = random.uniform(0,1) #exploit vs explore\n",
    "        \n",
    "        if eVe > epsilon: #exploit\n",
    "            action = np.argmax(Qtable[state,:]) \n",
    "            \n",
    "        else: #explore\n",
    "            action = env.action_space.sample()\n",
    "        \n",
    "        new_state, reward, done, info = env.step(action) #set values based on action taken\n",
    "        Qtable[state,action]= Qtable[state,action] + learning_rate*(reward+gamma*np.max(Qtable[new_state,:])-Qtable[state,action])\n",
    "        state = new_state\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        epsilon = min_epsilon + (max_epsilon-min_epsilon)*np.exp(-decay_rate*episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      "Episode: 0\n",
      "Score 7\n",
      "************************\n",
      "Episode: 1\n",
      "Score 13\n",
      "************************\n",
      "Episode: 2\n",
      "Score 7\n",
      "************************\n",
      "Episode: 3\n",
      "Score 10\n",
      "************************\n",
      "Episode: 4\n",
      "Score 12\n",
      "************************\n",
      "Episode: 5\n",
      "Score 12\n",
      "************************\n",
      "Episode: 6\n",
      "Score 9\n",
      "************************\n",
      "Episode: 7\n",
      "Score 9\n",
      "************************\n",
      "Episode: 8\n",
      "Score 8\n",
      "************************\n",
      "Episode: 9\n",
      "Score 11\n",
      "************************\n",
      "Episode: 10\n",
      "Score 7\n",
      "************************\n",
      "Episode: 11\n",
      "Score 7\n",
      "************************\n",
      "Episode: 12\n",
      "Score 7\n",
      "************************\n",
      "Episode: 13\n",
      "Score 4\n",
      "************************\n",
      "Episode: 14\n",
      "Score 12\n",
      "************************\n",
      "Episode: 15\n",
      "Score 9\n",
      "************************\n",
      "Episode: 16\n",
      "Score 11\n",
      "************************\n",
      "Episode: 17\n",
      "Score 8\n",
      "************************\n",
      "Episode: 18\n",
      "Score 8\n",
      "************************\n",
      "Episode: 19\n",
      "Score 8\n",
      "************************\n",
      "Episode: 20\n",
      "Score 8\n",
      "************************\n",
      "Episode: 21\n",
      "Score 6\n",
      "************************\n",
      "Episode: 22\n",
      "Score 10\n",
      "************************\n",
      "Episode: 23\n",
      "Score 8\n",
      "************************\n",
      "Episode: 24\n",
      "Score 6\n",
      "************************\n",
      "Episode: 25\n",
      "Score 12\n",
      "************************\n",
      "Episode: 26\n",
      "Score 8\n",
      "************************\n",
      "Episode: 27\n",
      "Score 4\n",
      "************************\n",
      "Episode: 28\n",
      "Score 15\n",
      "************************\n",
      "Episode: 29\n",
      "Score 7\n",
      "************************\n",
      "Episode: 30\n",
      "Score 11\n",
      "************************\n",
      "Episode: 31\n",
      "Score 11\n",
      "************************\n",
      "Episode: 32\n",
      "Score 6\n",
      "************************\n",
      "Episode: 33\n",
      "Score 10\n",
      "************************\n",
      "Episode: 34\n",
      "Score 9\n",
      "************************\n",
      "Episode: 35\n",
      "Score 5\n",
      "************************\n",
      "Episode: 36\n",
      "Score 5\n",
      "************************\n",
      "Episode: 37\n",
      "Score 9\n",
      "************************\n",
      "Episode: 38\n",
      "Score 6\n",
      "************************\n",
      "Episode: 39\n",
      "Score 10\n",
      "************************\n",
      "Episode: 40\n",
      "Score 9\n",
      "************************\n",
      "Episode: 41\n",
      "Score 8\n",
      "************************\n",
      "Episode: 42\n",
      "Score 7\n",
      "************************\n",
      "Episode: 43\n",
      "Score 8\n",
      "************************\n",
      "Episode: 44\n",
      "Score 8\n",
      "************************\n",
      "Episode: 45\n",
      "Score 7\n",
      "************************\n",
      "Episode: 46\n",
      "Score 10\n",
      "************************\n",
      "Episode: 47\n",
      "Score 11\n",
      "************************\n",
      "Episode: 48\n",
      "Score 11\n",
      "************************\n",
      "Episode: 49\n",
      "Score 8\n",
      "************************\n",
      "Episode: 50\n",
      "Score 10\n",
      "************************\n",
      "Episode: 51\n",
      "Score 4\n",
      "************************\n",
      "Episode: 52\n",
      "Score 11\n",
      "************************\n",
      "Episode: 53\n",
      "Score 7\n",
      "************************\n",
      "Episode: 54\n",
      "Score 8\n",
      "************************\n",
      "Episode: 55\n",
      "Score 7\n",
      "************************\n",
      "Episode: 56\n",
      "Score 9\n",
      "************************\n",
      "Episode: 57\n",
      "Score 8\n",
      "************************\n",
      "Episode: 58\n",
      "Score 12\n",
      "************************\n",
      "Episode: 59\n",
      "Score 4\n",
      "************************\n",
      "Episode: 60\n",
      "Score 7\n",
      "************************\n",
      "Episode: 61\n",
      "Score 6\n",
      "************************\n",
      "Episode: 62\n",
      "Score 11\n",
      "************************\n",
      "Episode: 63\n",
      "Score 9\n",
      "************************\n",
      "Episode: 64\n",
      "Score 9\n",
      "************************\n",
      "Episode: 65\n",
      "Score 4\n",
      "************************\n",
      "Episode: 66\n",
      "Score 4\n",
      "************************\n",
      "Episode: 67\n",
      "Score 11\n",
      "************************\n",
      "Episode: 68\n",
      "Score 5\n",
      "************************\n",
      "Episode: 69\n",
      "Score 13\n",
      "************************\n",
      "Episode: 70\n",
      "Score 8\n",
      "************************\n",
      "Episode: 71\n",
      "Score 7\n",
      "************************\n",
      "Episode: 72\n",
      "Score 9\n",
      "************************\n",
      "Episode: 73\n",
      "Score 9\n",
      "************************\n",
      "Episode: 74\n",
      "Score 10\n",
      "************************\n",
      "Episode: 75\n",
      "Score 7\n",
      "************************\n",
      "Episode: 76\n",
      "Score 8\n",
      "************************\n",
      "Episode: 77\n",
      "Score 11\n",
      "************************\n",
      "Episode: 78\n",
      "Score 6\n",
      "************************\n",
      "Episode: 79\n",
      "Score 9\n",
      "************************\n",
      "Episode: 80\n",
      "Score 7\n",
      "************************\n",
      "Episode: 81\n",
      "Score 9\n",
      "************************\n",
      "Episode: 82\n",
      "Score 7\n",
      "************************\n",
      "Episode: 83\n",
      "Score 5\n",
      "************************\n",
      "Episode: 84\n",
      "Score 5\n",
      "************************\n",
      "Episode: 85\n",
      "Score 7\n",
      "************************\n",
      "Episode: 86\n",
      "Score 7\n",
      "************************\n",
      "Episode: 87\n",
      "Score 10\n",
      "************************\n",
      "Episode: 88\n",
      "Score 12\n",
      "************************\n",
      "Episode: 89\n",
      "Score 9\n",
      "************************\n",
      "Episode: 90\n",
      "Score 8\n",
      "************************\n",
      "Episode: 91\n",
      "Score 13\n",
      "************************\n",
      "Episode: 92\n",
      "Score 11\n",
      "************************\n",
      "Episode: 93\n",
      "Score 7\n",
      "************************\n",
      "Episode: 94\n",
      "Score 10\n",
      "************************\n",
      "Episode: 95\n",
      "Score 6\n",
      "************************\n",
      "Episode: 96\n",
      "Score 8\n",
      "************************\n",
      "Episode: 97\n",
      "Score 11\n",
      "************************\n",
      "Episode: 98\n",
      "Score 4\n",
      "************************\n",
      "Episode: 99\n",
      "Score 5\n",
      "************************\n",
      "Score over time: 8.36\n"
     ]
    }
   ],
   "source": [
    "#Let's play the game!\n",
    "\n",
    "env.reset()\n",
    "rewards = []\n",
    "\n",
    "for episode in range(test_episodes):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_rewards = 0\n",
    "    print(\"************************\")\n",
    "    print(\"Episode:\", episode)\n",
    "    \n",
    "    for step in range(max_moves):\n",
    "        action = np.argmax(Qtable[state,:])\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        total_rewards+=reward\n",
    "        \n",
    "        if done:\n",
    "            rewards.append(total_rewards)\n",
    "            print(\"Score\", total_rewards)\n",
    "            break\n",
    "        \n",
    "        state = new_state\n",
    "env.close()\n",
    "print(\"************************\")\n",
    "print(\"Score over time: \" + str(sum(rewards)/test_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
